\documentclass[12pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\usepackage{setspace}
\onehalfspacing

\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{times}
\renewcommand{\ttdefault}{cmtt}
\usepackage{amsmath}
\usepackage{graphicx} % for graphics files
\usepackage{tabu}

% Draw figures yourself
\usepackage{tikz} 
\usetikzlibrary{shapes,arrows}

% writing elements
\usepackage{mhchem}

% The float package HAS to load before hyperref
\usepackage{float} % for psuedocode formatting
\usepackage{xspace}

% from Denovo Methods Manual
\usepackage{mathrsfs}
\usepackage[mathcal]{euscript}
\usepackage{color}
\usepackage{array}

\usepackage[pdftex]{hyperref}
\usepackage[parfill]{parskip}

% math syntax
\newcommand{\nth}{n\ensuremath{^{\text{th}}} }
\newcommand{\ve}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\Macro}{\ensuremath{\Sigma}}
\newcommand{\rvec}{\ensuremath{\vec{r}}}
\newcommand{\vecr}{\ensuremath{\vec{r}}}
\newcommand{\omvec}{\ensuremath{\hat{\Omega}}}
\newcommand{\vOmega}{\ensuremath{\hat{\Omega}}}
\newcommand{\sigs}{\ensuremath{\Sigma_s(\rvec,E'\rightarrow E,\omvec'\rightarrow\omvec)}}
\newcommand{\el}{\ensuremath{\ell}}
\newcommand{\sigso}{\ensuremath{\Sigma_{s,0}}}
\newcommand{\sigsi}{\ensuremath{\Sigma_{s,1}}}
\newcommand{\ep}{\ensuremath{\varepsilon}}
%---------------------------------------------------------------------------
%---------------------------------------------------------------------------
\begin{document}
\begin{center}
{\bf NE 250, F15\\
November 30, 2015 
}
\end{center}

We've talked about how to discretize the transport equation in energy using the \textit{multigroup approximation,} in angle using $S_N$, $P_N$, or $SP_N$, and in space using \textit{diamond difference} or an equivalent spatial scheme. \\
If we're solving an eigenvalue problem, we also need to deal with that.\\
Great. Now how to we actually solve it all? 

Well, we break this into two iteration levels if there isn't fission and three iteration levels if there is fission:
\begin{enumerate}
\item \textbf{inner iterations}: solve the space-angle component for each energy group. This uses the sweeps that we talked about last time. \\
We get to choose what kind of solver we would like to use. \\
The most basic and traditional is source iteration; a more advanced choice is a Krylov solver.

\item \textbf{outer iterations}: solve the energy component; after we've dealt with space and angle in each group, we iterate on energy if necessary. \\
The most common solver is Gauss Seidel, with Jacobi or block Jacobi being simpler and multigroup Krylov solves being a new option.

\item \textbf{eigenvalue iterations}: after the space, angle, and energy has been converged, we update the eigenvalue and eigenvector until they converge.\\
The historic solver is Power Iteration.\\
Other choices are shifted inverse iteration (Wielandt's method and Rayleigh Quotient Iteration are extensions of this), Arnoldi, and Davidson.
\end{enumerate}
At each step each solver has pros and cons. We think about things like convergence rate, ability to parallelize, and ability to precondition/accelerate.\\
Each iteration level often comes with its own set of preconditioners and/or acceleration strategies.


%-------------------------------------------------------------------
%-------------------------------------------------------------------
\textit{Inner Iterations:}\\
Inner iteration index is $p$, we've suppressed the energy index for now.\\
We need to know $\phi_{l,i}^{(p-1)}$, so for $p=1$ we have an initial guess for $\phi_{l,i}^{(0)}$. \\
This is basically the source iteration method, but can be readily adapted to other strategies; for each energy group:

% Define block styles
\tikzstyle{decision} = [diamond, draw,% fill=blue!20, 
    text width=5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw,% fill=blue!20, 
    text width=10em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse, node distance=3cm, %fill=red!20, 
    minimum height=2em]
%
\begin{center}
\begin{tikzpicture}[node distance = 2.5cm, auto]
    % Place nodes
    \node [block] (init) {Angular\\moments, $\phi_{l,i}^{(p-1)}$};   
    \node [cloud, right of=init, node distance=5cm] (input) {$\phi_{l,i}^{(0)}$};
    \node [block, below of=init] (source) {scattering formula + external source: $q_{n,1}^{(p-1)}$};
    \node [block, below of=source, node distance=3cm] (sweep) {angular flux: $\psi_{n,i}^{(p)}$};
        \node [block, below of=sweep] (moments) {update angular flux moments: $\phi_{l,i}^{(p)}$};
    \node [decision, below of=moments, node distance=3cm] (converged) {$\phi_{0,i}$ converged?};
    \node [block, right of=converged, node distance=5cm] (stop) {terminate successfully:\\ solution is $\phi_{l,i}^{(p)}$};
    \node [decision, left of=converged, node distance=5cm] (max) {$p \geq p_{\max}$?};
    \node [block, left of=sweep, node distance=5cm] (update) {$\phi_{l,i}^{(p-1)}= \phi_{l,i}^{(p)}$\\$p = p+1$};
    \node [block, below of=max, node distance=3cm] (end) {terminate \textit{un}successfully};
    % Draw edges
    \path [line] (init) -- (source);
    \path [line] (source) -- node {perform mesh sweep}(sweep);
    \path [line] (sweep) -- (moments);    
    \path [line] (moments) -- (converged);
    \path [line] (converged) -- node {no}(max);
    \path [line] (converged) -- node {yes}(stop);    
    \path [line] (max) -- node {yes}(end);    
    \path [line] (max) -- node {no}(update);    
    \path [line] (update) |- (init);
    \path [line,dashed] (input) -- (init);
\end{tikzpicture}
\end{center}
We can think through convergence by thinking of the physical interpretation of $\psi_n^{(p)}$ with $p=0$ having an initial guess for $\psi$ and $q_n^{(0)} = s_n$.
\begin{itemize}
\item $p=1$: $\psi_n^{(1)} = \ve{A} s_n$ is the uncollided flux. We plug this into the moment formula and that into the formula for $q_n$, the rhs:
\[
q_{n,i}^{(1)} = \underbrace{\sum_{l=0}^L (2l+1) P_l(\mu_n) \Sigma_{sl,i} \phi_{l,i}^{(1)}}_{b_{n,i}^{(1)}} + s_{n,i}
\]

\item  $p=2$: $\psi_n^{(2)}$ is the flux of neutrons that have had \textit{up to} 1 collision
\[
\psi_n^{(2)} = \ve{A} q_{n}^{(1)} = \underbrace{\ve{A} b_n^{(1)}}_{\tilde{\psi}_n^{(2)}} + \underbrace{\ve{A}s_n}_{\psi_n^{(1)}}
\]
$\psi_n^{(1)}$ is the uncollided flux, therefore $\tilde{\psi}_n^{(2)}$ is the flux of neutrons with \textit{exactly} 1 collision.

\item For a general $p$: the flux of neutrons with up to $p-1$ collisions
\begin{align*}
\psi_n^{(p)} &= \ve{A} q_{n}^{(p-1)} = \ve{A} b_n^{(p-1)} + \ve{A} b_n^{(p-2)} + \dots \ve{A}s_n\\
&= \tilde{\psi}_n^{(p)} + \tilde{\psi}_n^{(p-1)} + \dots + \psi_n^{(1)}
\end{align*}

\item Convergence requires $|\phi_0^{(p)} - \phi_0^{(p-1)}|$ be small where
\[
\phi_0^{(p)} - \phi_0^{(p-1)} = \frac{1}{2} \sum_{n=0}^N w_n[\underbrace{\psi_n^{(p)} - \psi_n^{(p-1)}}_{\tilde{\psi}_n^{(p)}}] \:.
\]
This means the we need $\tilde{\psi}_n^{(p)}$, the flux of neutrons with exactly $p-1$ collisions to be small.

\item Thus, inner iteration convergence will be rapid if few neutrons survive many collisions: large leakage, large removal (absorption and/or large up or downscattering within a group).
\end{itemize}
%
Okay, but what about dealing with groups? We need to think of it from an inner iteration and outer iteration standpoint.\\
If we have only downscattering, $\Sigma_{s,l,gg'}=0$ when $g' > g$, we only need one set of inner iterations (ii) and we are finished:
% 
\begin{itemize}
\item We solve group 1 using the external source for group 1; $\psi_{n,g=1}$ is the final solution in that group. 
\item Next we compute the distributed source in $g=2$ from the external source plus the downscattering source from group 1. 
\item We solve $g=2$ with ii, $\psi_{n,g=2}$ is the final solution in that group.
\item And so on through $g=G$, then we are completely solved for all groups.
\end{itemize}
%
However, we often have upscattering (where lower groups contribute back to higher groups) as well as neutrons coming from fission (which depends on the flux in other groups). One set of inner iterations won't do that for us, so we need 


%-------------------------------------------------------------------
%-------------------------------------------------------------------
\textit{Outer Iterations:} \\
We will write this in words for Gauss Seidel for outer iteration index $J$:
%
\begin{itemize}
\item Construct the source for group 1 as the external source + upscattering from $g>1$ and fission using $J-1$ flux values.
\item Apply ii, now we have a new outer iterate for $\psi_{n,g=1}$.
\item The $g=2$ source is the external source + downscattering from $g=1$ using the $J$ iterate flux + upscattering from $g>2$ and fission from the $J-1$ iterate flux. 
\item At $g=G$, test convergence for each group:
\[
|\phi_{0,g}^{(J)} - \phi_{0,g}^{(J-1)}| < \epsilon \quad \text{or} \quad |\frac{\phi_{0,g}^{(J)}}{\phi_{0,g}^{(J-1)}} - 1| < \epsilon \quad \forall g \:.
\]
\end{itemize}
I had mentioned outer iteration solution options. To consider these, we will think of our problem as looking like $\ve{A} \phi = b$ (which we won't talk about much further today).

\textbf{Jacobi}, probably the simplest method, has the algorithm, for $g = 1, \dots, G$:
\[\phi^{(J)}_g = \frac{1}{a_{gg}}(b_g - \sum_{g'=1}^{g-1} a_{gg'} \phi_{g'}^{(J-1)} - \sum_{g'=g+1}^{G} a_{gg'} \phi_{g'}^{(J-1)})\:.\]

Jacobi is unconditionally stable and linearly convergent, but may converge very slowly in some situations (we leave detailed analysis of this to another class). \\
Jacobi isn't a very sophisticated method, but it's easy to parallelize. Why might that be? \\The Jacobi method is order independent since all terms on the right are at the old iteration level. 

\textbf{Gauss Seidel Iteration} is a simple modification of Jacobi, but becomes a bit more complicated. (How can you think of changing Jacobi than might incorporate more information that we already have?)\\
The algorithm for this method is, for $g = 1, \dots, G$:
\[ \phi^{(J)}_g = \frac{1}{a_{gg}}(b_g - \sum_{g'=1}^{g-1} a_{gg'} \phi_{g'}^{(J)} - \sum_{g'=g+1}^{G} a_{gg'} \phi_{g'}^{(J-1)}) \:.\]
%
Gauss Seidel is also unconditionally stable and linearly convergent, and 
converges twice as fast as Jacobi (not proven here). \\
However, both methods may converge very slowly\textemdash especially in highly scattering systems.\\
Gauss Seidel is not so easy to parallelize. Why not? \\The GS method is order dependent, containing terms on the right hand side at both the new and old iterates.

For completeness, \textbf{Richardson/Source Iteration}, which we used for our inner iterations, is given as well.\\ 
There are two very similar versions. In \textit{non-stationary}, Richardson iteration that uses some scalar $\omega$ that gets updated.\\
If $\omega^{(p-1)}$ is constant, then this is the \textit{stationary} Richardson method. \\ 
If $\omega = 1$ this is source iteration.\\
The algorithm for this method, which is within each group, is:
\[\phi_{i}^{(p)} =  \phi^{(p-1)}_{i} - \omega^{(p-1)} \sum_{i'=1}^{I} a_{ii'}\phi_{i'}^{(p-1)} + \omega^{(p-1)} b_i \:.\]
%
The speed of convergence and is determined by $c = \Sigma_s / \Sigma_t$. For problems dominated by scattering, this method will converge very slowly. 


%-------------------------------------------------------------------
%-------------------------------------------------------------------
\textit{Eigenvalue Iterations:}\\
The generalized eigenvalue problem takes the form $\ve{B}x = \mu \ve{C}x$ and can be transformed into an ordinary eigenvalue problem, $\ve{A}x= \lambda x$. Both forms have the same right eigenvectors. If $\ve{C}$ is non-singular, then $\ve{A} = \ve{C}^{-1}\ve{B}$.

Let $\sigma(\ve{A}) \equiv \{\lambda \in \mathbb{C} : rank(\ve{A} - \lambda \ve{I}) \le n\}$ be the spectrum of $\ve{A}$, where the elements in the set are the eigenvalues and $\mathbb{C}$ is the set of complex numbers.\\ %The eigenvalues can be characterized as the $n$ roots of the polynomial $p_{\ve{A}}(\lambda) \equiv det(\lambda \ve{I} - \ve{A})$. 
Each distinct eigenvalue in $\sigma(\ve{A})$ has a corresponding nonzero vector $x$ such that $\ve{A}x_{i} = \lambda_{i} x_{i}$ for $i = 1,...,n$.\\
It will be assumed that the eigenvalues are ordered as $|\lambda_{1}| > |\lambda_{2}| \ge \dots \ge |\lambda_{n}| \ge 0$. 

Power iteration (PI) is an old and straightforward algorithm for finding an eigenvalue/vector pair. \\
The basic idea is that any nonzero vector can be written as a linear combination of the eigenvectors of $\ve{A}$ because the eigenvectors are linearly independent, namely $v_0 = \gamma_1 x_1 + \gamma_2 x_2 + \cdots + \gamma_n x_n$ where $x_{j}$ is the $j$th eigenvector and $\gamma_{j}$ is some constant.

Another fact that is used to understand power iteration is that $\ve{A}^k x_i = \lambda_i^k x_i$. Thus
%
\begin{equation}
  \ve{A}^k v_{0} = \gamma_1 \lambda_1^k x_1 + \gamma_2 \lambda_2^k x_2 + \cdots + \gamma_n \lambda_n^k x_n \:.
  \label{eq:Ak}
\end{equation}
%
Since $|\lambda_1| > |\lambda_i|, i \ne 1$, the first term in the expansion will dominate as $k \to \infty$ and $\ve{A}^k v_{0}$ therefore becomes an increasingly accurate approximation to $x_1$.\\ 
In practice, it is desirable to avoid exponentiating a matrix and it is helpful to normalize $v_0$ in order to avoid possible over or underflow. This leads to this algorithm:\\
Given $\ve{A}$ and $v_0$, $v = \frac{v_{0}}{||v_{0}||}$, until convergence do:
\begin{itemize}
    \item $w = \ve{A}v$
    \item $v = \frac{w}{||w||}$
    \item $\lambda = v^{T}\ve{A}v$
\end{itemize}
%
The error is reduced in each iteration (analysis omitted here) by a factor of $|\frac{\lambda_{2}}{\lambda_{1}}|$, which is called the dominance ratio. \\
If $\lambda_2$ is close to $\lambda_1$, then this ratio will be close to 1 and the method will converge very slowly. \\
If $\lambda_2$ is far from $\lambda_1$, then convergence will happen much more quickly. \\
Put simply, PI is better suited for problems where $\ve{A}$ has eigenvalues that are well separated.

Power iteration is very attractive because it only requires matrix-vector products and two vectors of storage space. \\
Because of its simplicity and low storage cost, PI has been widely used in the transport community for criticality problems for quite some time. \\
Many current codes use an acceleration method with PI, or have moved away from it altogether because of the slow convergence for many problems of interest. \\
Nevertheless it is still used in some codes, has historical relevance, and is used in many studies as a base comparison case. 

\vspace*{1 em}
Relating this more concretely to the transport equation: (let's look at multi-D)
\\
The fixed source for group $g$ is
\[
q_{n,i,j}^g = \sum_{g'=1; g' \neq g}^G \sum_{l=0}^L \sum_{m=-l}^l (2 - \delta_{m0})Y_{lm}^e(\mu_n, \eta_n) \Sigma_{s,l,i,j}(g' \rightarrow g) \phi_{l,i,j}^{m,g'} + \frac{\chi^g}{k}\bigl(\underbrace{\sum_{g'=1}^G \nu \Sigma_{f,i,j}^{g'} \phi_{0,i,g}^{g'}}_{F_{ij}} \bigr)
\]
and
\[
\phi_{l,i,j}^{m,g} \equiv \frac{1}{4}\sum_{n=1}^{(N+2)N/2} w_n Y_{lm}^e(\mu_n, \eta_n) \psi_{n,i,j}^g\:.
\]

The \textit{Power Iteration} algorithm built into GS is:
\begin{itemize}
\item start with the previous iterate: $F_{ij}^{(J-1)}$ and $k^{(J-1)}$
\item compute $q_{F,i,j}^{g,(J-1)} = \chi_g / k^(J-1) * F_{ij}^{(J-1)}$
\item conduct an outer iteration by doing a full set of inners (fission + upscattering from $(J-1)$ and downscattering from $(J)$). 

\item update the eigenvalue:
\[
k^{(J)} = \dfrac{\sum_{i,j} w_{ij} \Delta x_i \Delta y_j F_{ij}^{(J)}}{\frac{1}{k^{(J-1)} }\sum_{i,j} w_{ij} \Delta x_i \Delta y_j F_{ij}^{(J-1)}}
\]
where $w_{ij}$ is a weight determined by your method and this is the ``generational" definition of $k_{eff}$.

\item Compare $\phi_{0,i,j}^{(J)}$ to $\phi_{0,i,j}^{(J-1)}$ *and* $k^{(J)}$ to $k^{(J-1)}$
\end{itemize}

We can now update our picture to include all of this:

\begin{center}
\begin{tikzpicture}[node distance = 2.5cm, auto]
    % Place nodes and draw edges
    \node [block] (sweep) {mesh sweep};    
    \node [below of=sweep] (hold) {};
    \node [decision, right of=hold] (gconv) {group fluxes converged?};
    \node [block, left of=hold, node distance=4cm] (gscattering) {compute group self-scattering};
    \path [line] (sweep) -| node{group flux angular moments}(gconv);
    \path [line] (gconv) -- node {no}(gscattering);
    \path [line] (gscattering) |- node {1-speed fixed src}(sweep);
    \node [decision, below of=gconv, node distance=3.5cm] (lg) {last group?};
    \path [line] (gconv) -- node{yes}(lg);
    \node [block, left of=lg, node distance=9.5cm] (next) {Next Group Source\\ 1. downscatter:\\this outer \\ 2. upscatter: prev outer \\ 3. fission density};
    \path [line] (lg) -- node{no}(next);
    \path [line] (next) |- (sweep);
    \node [decision, below of=lg, node distance=3.5cm] (conv) {$\phi_0^g \forall g$ and $k$ converged?};
    \node [block, left of=conv,  node distance=7cm] (fsource) {compute new \\fission source $F_{ij}$ and $k$};
    \node [block, below of=conv, node distance=3cm] (term) {terminate successfully};
    \path [line] (lg) -- node{yes}(conv);
    \path [line] (conv) -- node{no}(fsource);
    \path [line] (fsource) -- (next);
    \path [line] (conv) -- node{yes}(term);
\end{tikzpicture}
\end{center}

\end{document}